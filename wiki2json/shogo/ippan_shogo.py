import os
import json
from itertools import zip_longest

def convert_markdown_file_to_json(input_file, output_file):
    """
    Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€JSONå½¢å¼ã«å¤‰æ›ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
    """
    try:
        if not os.path.exists(input_file):
            print(f"ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{input_file}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return False

        with open(input_file, 'r', encoding='utf-8') as f:
            markdown_content = f.read()

        lines = [line.strip() for line in markdown_content.strip().split('\n')]
        
        headers = ["ãƒ¡ãƒ€ãƒªã‚ªãƒ³", "ãƒ¬ã‚¢", "äºŒã¤å", "æ¥é ­", "æ¥å°¾", "æ”»æ’ƒ", "é˜²å¾¡", "é€Ÿåº¦", "çŸ¥åŠ›", "ç‰¹æ”»", "åŠ è­·", "è¿½åŠ ã‚¹ã‚­ãƒ«"]
        
        data = []
        data_lines = [line for line in lines[3:] if line.strip()]
        
        for line in data_lines:
            # å„è¡Œã‚’'|'ã§åˆ†å‰²ã€‚å…ˆé ­ã¨æœ«å°¾ã®ç©ºã®è¦ç´ ã‚’å‰Šé™¤
            values = line.split('|')[1:-1]
            values = [v.strip() for v in values]
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã¨å€¤ã®ãƒšã‚¢ã‚’ç¢ºå®Ÿã«ä½œæˆ
            item_data = list(zip_longest(headers, values, fillvalue=''))

            item = {}
            for key, value in item_data:
                item[key] = value

            processed_item = {
                "ãƒ¡ãƒ€ãƒªã‚ªãƒ³": item.get("ãƒ¡ãƒ€ãƒªã‚ªãƒ³"),
                "ãƒ¬ã‚¢": int(item.get("ãƒ¬ã‚¢")) if item.get("ãƒ¬ã‚¢") and item.get("ãƒ¬ã‚¢").isdigit() else 0,
                "äºŒã¤å": item.get("äºŒã¤å"),
                "æ¥ç¶š": {
                    "æ¥é ­": item.get("æ¥é ­") if item.get("æ¥é ­") == "â—" else "",
                    "æ¥å°¾": item.get("æ¥å°¾") if item.get("æ¥å°¾") == "â—" else ""
                },
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–": {
                    "æ”»æ’ƒ": int(item.get("æ”»æ’ƒ")) if item.get("æ”»æ’ƒ") and item.get("æ”»æ’ƒ").lstrip('-').isdigit() else 0,
                    "é˜²å¾¡": int(item.get("é˜²å¾¡")) if item.get("é˜²å¾¡") and item.get("é˜²å¾¡").lstrip('-').isdigit() else 0,
                    "é€Ÿåº¦": int(item.get("é€Ÿåº¦")) if item.get("é€Ÿåº¦") and item.get("é€Ÿåº¦").lstrip('-').isdigit() else 0,
                    "çŸ¥åŠ›": int(item.get("çŸ¥åŠ›")) if item.get("çŸ¥åŠ›") and item.get("çŸ¥åŠ›").lstrip('-').isdigit() else 0,
                    "ç‰¹æ”»": item.get("ç‰¹æ”»") 
                },
                "èƒ½åŠ›ä»˜ä¸": {
                    "åŠ è­·": item.get("åŠ è­·", None) if item.get("åŠ è­·") else None,
                    "è¿½åŠ ã‚¹ã‚­ãƒ«": item.get("è¿½åŠ ã‚¹ã‚­ãƒ«", None) if item.get("è¿½åŠ ã‚¹ã‚­ãƒ«") else None
                }
            }
            data.append(processed_item)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ… '{input_file}' ã‹ã‚‰ '{output_file}' ã¸ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        return True

    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« '{input_file}' ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

def process_data_directory(directory):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã® .txt ãƒ•ã‚¡ã‚¤ãƒ«ã‚’JSONã«å¤‰æ›ã—ã¾ã™ã€‚
    """
    if not os.path.isdir(directory):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{directory}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    print(f"ğŸ” ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{directory}' å†…ã® .txt ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    
    processed_count = 0
    for filename in os.listdir(directory):
        if filename.endswith(".txt"):
            input_path = os.path.join(directory, filename)
            base_name = os.path.splitext(filename)[0]
            output_path = os.path.join(directory, f"{base_name}.json")
            
            if convert_markdown_file_to_json(input_path, output_path):
                processed_count += 1
    
    print(f"\nğŸ‰ å¤‰æ›å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚åˆè¨ˆ {processed_count} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›ã•ã‚Œã¾ã—ãŸã€‚")

if __name__ == '__main__':
    if not os.path.exists('data'):
        os.makedirs('data')

    process_data_directory('data')